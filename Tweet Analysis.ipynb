{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = '#########'\n",
    "CONSUMER_SECRET='#########'\n",
    "ACCESS_TOKEN='#########'\n",
    "ACCESS_SECRET='#########'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk.classify.util\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "import tweepy\n",
    "from random import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "#from credentials import *\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('twitter_samples')\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.stem import PorterStemmer # this module removes words that mean the same but have\n",
    "different tenses\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tweepy import Stream, OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "\n",
    "emoticons_happy = {':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}', ':^)', ':-D', ':D', '8-D',\n",
    " '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D', '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P',\n",
    " ':-P', ':P', 'X-P', 'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)', '<3'}\n",
    "emoticons_sad = {':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<', ':-[', ':-<', '=\\\\', '=/',\n",
    " '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c', ':c', ':{', '>:\\\\', ';('}\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "# Tweepy\n",
    "def twitter_setup():\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "def extraction(name):\n",
    "    extractor = twitter_setup()\n",
    "    tweets = extractor.user_timeline(screen_name=name, count=200)\n",
    "    data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "    data['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "    data['ID'] = np.array([tweet.id for tweet in tweets])\n",
    "    data['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "    data['Likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "    data['RTs'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "    data['sentiment'] = np.array([\"\" for tweet in tweets])\n",
    "    #display(data.head(10))\n",
    "    data.to_csv('Data_collected.csv', sep=',')\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r\"https?://.*[\\r\\n]*\", '', tweet)\n",
    "    # remove hashtags\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    #print(tweet)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    #print(tokens)\n",
    "    stemmer = PorterStemmer()\n",
    "    cleaned_tweets = []\n",
    "    for w in tokens:\n",
    "    if w not in stopwords_english and w not in emoticons and w not in string.punctuation:\n",
    "    stem_word = stemmer.stem(w)\n",
    "    #print(stem_word)\n",
    "    cleaned_tweets.append(stem_word)\n",
    "    #print(cleaned_tweets)\n",
    "    return cleaned_tweets\n",
    "\n",
    "def get_words_and_clean(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(\"[^a-zA-Z]\", \" \", s)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    final = \"\"\n",
    "    for a in s.split():\n",
    "    if not a in stops:\n",
    "    final += str(a + \" \")\n",
    "    return final\n",
    "\n",
    "def bag_of_words(tweet):\n",
    "    words = clean_tweet(tweet)\n",
    "    words_dictionary = dict([word, True] for word in words)\n",
    "    return words_dictionary\n",
    "\n",
    "def ml():\n",
    "    pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "    neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "    pos_tweets_set = []\n",
    "    for tweet in pos_tweets:\n",
    "    pos_tweets_set.append((bag_of_words(tweet), 'pos'))\n",
    "    #print(pos_tweets_set)\n",
    "    neg_tweets_set = []\n",
    "    for tweet in neg_tweets:\n",
    "    neg_tweets_set.append((bag_of_words(tweet), 'neg'))\n",
    "    test_set = pos_tweets_set[:1000] + neg_tweets_set[:1000]\n",
    "    train_set = pos_tweets_set[1000:] + neg_tweets_set[1000:]\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    accuracy = classify.accuracy(classifier, test_set)\n",
    "    # print(accuracy)\n",
    "    joblib.dump(classifier, 'ml_model.pkl')\n",
    "\n",
    "def stats(no_of_pos, no_of_neg):\n",
    "    df = pd.DataFrame.from_csv('Data_collected.csv', sep=',')\n",
    "    total_likes,rts = 0,0\n",
    "    for row in range(df.shape[0]):\n",
    "    total_likes+=df.loc[row, 'Likes']\n",
    "    rts +=df.loc[row,'RTs']\n",
    "    print('Total tweets considered: ',no_of_neg+no_of_pos)\n",
    "    print('No of positive tweets: ', no_of_pos)\n",
    "    print('No of negative tweets: ', no_of_neg)\n",
    "    print('Total likes: ',total_likes)\n",
    "    print('Total rates',rts)\n",
    "    if (no_of_pos > no_of_neg):\n",
    "    print('The overall attitude recently has been positive.')\n",
    "    else:\n",
    "    print('The overall attitude recently has been negative.')\n",
    "    print('Check generated csv file for individual predictions ')\n",
    "\n",
    "def sentiment_analysis():\n",
    "    ml()\n",
    "    no_of_pos, no_of_neg = 0, 0\n",
    "    df = pd.DataFrame.from_csv('Data_collected.csv', sep=',')\n",
    "    #print(df.head(10))\n",
    "    clf = joblib.load('ml_model.pkl')\n",
    "    #print(clf.show_most_informative_features(5))\n",
    "    for row in range(df.shape[0]):\n",
    "    prediction = clf.classify(bag_of_words(str(df['Tweets'][row])))\n",
    "    df.loc[row, 'sentiment'] = prediction\n",
    "    if prediction == 'pos':\n",
    "    no_of_pos += 1\n",
    "    else:\n",
    "    no_of_neg += 1\n",
    "    df.to_csv('Data_found.csv', sep=',')\n",
    "    stats(no_of_pos, no_of_neg)\n",
    "\n",
    "name = input(\"Enteir twitter id: \")\n",
    "extraction(name)\n",
    "sentiment_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
